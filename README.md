# SemEval-Style Clarity & Evasion Detection (QEvasion / CLARITY)

This repository contains our work toward a SemEval-style system for detecting  
**clarity** and **evasion techniques** in political questionâ€“answer pairs.

The project currently uses the [QEvasion](https://huggingface.co/datasets/ailsntua/QEvasion) dataset,  
which includes presidential interview questions and answers annotated for:

- `clarity_label` â€“ high-level clarity of the answer
- `evasion_label` â€“ fine-grained evasion techniques

The goal is to build and evaluate models that can **unmask when a politician dodges a question**.

---

## ðŸŒ± Project Goals

- Build baseline models for:
  - **Clarity classification** â€“ clear vs. ambiguous/evasive responses.
  - **Fine-grained evasion type classification** â€“ 9+ evasion strategies.
- Explore **transformer-based models** (e.g., RoBERTa / DeBERTa).
- Experiment with **multi-task learning**:
  - Shared encoder with two heads: one for clarity, one for evasion.
- Prepare the codebase to be extended toward a full **SemEval CLARITY task** system.

---

## ðŸ“‚ Project Structure

```text
semeval-clarity-evasion/
â”œâ”€â”€ configs/                  # (later) training & evaluation configs
â”œâ”€â”€ data/                     # local data cache (NOT tracked in git)
â”œâ”€â”€ notebooks/                # EDA & experiments (Jupyter)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ dataset_qevasion.py   # QEvasion dataset loader utilities
â”‚   â””â”€â”€ ...                   # (later) models, training & inference scripts
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

